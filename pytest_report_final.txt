============================= test session starts ==============================
platform darwin -- Python 3.9.6, pytest-8.3.5, pluggy-1.5.0 -- /Applications/Xcode.app/Contents/Developer/usr/bin/python3
cachedir: .pytest_cache
rootdir: /Users/xuyehua/Code/remote-terminal-mcp
plugins: anyio-4.9.0, cov-6.1.1, asyncio-1.0.0
asyncio: mode=strict, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
collecting ... collected 85 items

tests/tool_add_server_config/test_docker_config.py::TestDockerConfigCollector::test_configure_docker_skip PASSED [  1%]
tests/tool_add_server_config/test_fix_config_auto_creation_removal_20241222.py::TestConfigAutoCreationRemoval::test_config_directory_creation PASSED [  2%]
tests/tool_add_server_config/test_fix_config_auto_creation_removal_20241222.py::TestConfigAutoCreationRemoval::test_ensure_config_exists_no_auto_creation PASSED [  3%]
tests/tool_add_server_config/test_fix_config_auto_creation_removal_20241222.py::TestConfigAutoCreationRemoval::test_ensure_config_exists_with_invalid_config PASSED [  4%]
tests/tool_add_server_config/test_fix_config_auto_creation_removal_20241222.py::TestConfigAutoCreationRemoval::test_ensure_config_exists_with_valid_config PASSED [  5%]
tests/tool_add_server_config/test_fix_config_auto_creation_removal_20241222.py::TestConfigAutoCreationRemoval::test_ensure_config_exists_with_yaml_error PASSED [  7%]
tests/tool_add_server_config/test_fix_config_auto_creation_removal_20241222.py::TestConfigAutoCreationRemoval::test_get_existing_servers_no_config PASSED [  8%]
tests/tool_add_server_config/test_fix_config_auto_creation_removal_20241222.py::TestConfigAutoCreationRemoval::test_mcp_mode_behavior PASSED [  9%]
tests/tool_add_server_config/test_fix_save_config_parameter_mismatch_20250615.py::TestSaveConfigParameterFix::test_regression_server_deletion_scenario PASSED [ 10%]
tests/tool_add_server_config/test_fix_save_config_parameter_mismatch_20250615.py::TestSaveConfigParameterFix::test_save_config_parameter_name_consistency PASSED [ 11%]
tests/tool_add_server_config/test_fix_save_config_parameter_mismatch_20250615.py::TestSaveConfigParameterFix::test_save_config_with_merge_false PASSED [ 12%]
tests/tool_add_server_config/test_fix_save_config_parameter_mismatch_20250615.py::TestSaveConfigParameterFix::test_save_config_with_merge_parameter PASSED [ 14%]
tests/tool_add_server_config/test_interaction.py::TestUserInteraction::test_colored_print PASSED [ 15%]
tests/tool_add_server_config/test_interaction.py::TestUserInteraction::test_smart_input_default PASSED [ 16%]
tests/tool_add_server_config/test_interaction.py::TestUserInteraction::test_smart_input_with_mock PASSED [ 17%]
tests/tool_add_server_config/test_interactive_create_server_config.py::test_interactive_create_server_config FAILED [ 18%]
tests/tool_add_server_config/test_interactive_create_server_config_prefill.py::test_interactive_create_server_config_prefill PASSED [ 20%]
tests/tool_add_server_config/test_io.py::TestConfigIO::test_save_and_load_config PASSED [ 21%]
tests/tool_delete_server_config/test_fix_config_ux_and_prefill_bug.py::TestConfigUXPrefillFix::test_guided_setup_for_relay_server PASSED [ 22%]
tests/tool_delete_server_config/test_fix_config_ux_and_prefill_bug.py::TestConfigUXPrefillFix::test_update_relay_server_with_prefill_issues PASSED [ 23%]
tests/tool_disconnect_server/test_fix_terminal_cleanup_bug_20241222.py::TestTerminalCleanupBugFix::test_applescript_syntax_validation PASSED [ 24%]
tests/tool_disconnect_server/test_fix_terminal_cleanup_bug_20241222.py::TestTerminalCleanupBugFix::test_cleanup_configuration PASSED [ 25%]
tests/tool_disconnect_server/test_fix_terminal_cleanup_bug_20241222.py::TestTerminalCleanupBugFix::test_cleanup_disabled_behavior PASSED [ 27%]
tests/tool_disconnect_server/test_fix_terminal_cleanup_bug_20241222.py::TestTerminalCleanupBugFix::test_cleanup_script_no_pwd_command PASSED [ 28%]
tests/tool_disconnect_server/test_fix_terminal_cleanup_bug_20241222.py::TestTerminalCleanupBugFix::test_cleanup_terminals_method PASSED [ 29%]
tests/tool_disconnect_server/test_fix_terminal_cleanup_bug_20241222.py::TestTerminalCleanupBugFix::test_force_cleanup_script_generation PASSED [ 30%]
tests/tool_disconnect_server/test_fix_terminal_cleanup_bug_20241222.py::TestTerminalCleanupBugFix::test_force_cleanup_terminals_method PASSED [ 31%]
tests/tool_disconnect_server/test_fix_terminal_cleanup_bug_20241222.py::TestTerminalCleanupBugFix::test_project_path_detection PASSED [ 32%]
tests/tool_execute_command/test_fix_example_mcp_testing_20240622.py::TestMCPToolingFramework::test_reproduce_original_issue PASSED [ 34%]
tests/tool_execute_command/test_fix_example_mcp_testing_20240622.py::TestMCPToolingFramework::test_verify_fix PASSED [ 35%]
tests/tool_execute_command/test_fix_example_mcp_testing_20240622.py::TestMCPToolingFramework::test_boundary_conditions PASSED [ 36%]
tests/tool_execute_command/test_fix_example_mcp_testing_20240622.py::TestMCPToolingFramework::test_integration_with_other_components PASSED [ 37%]
tests/tool_execute_command/test_fix_example_mcp_testing_20240622.py::TestMCPToolingFramework::test_mcp_tool_error_handling PASSED [ 38%]
tests/tool_execute_command/test_fix_example_mcp_testing_20240622.py::TestMCPToolingFramework::test_mcp_tool_command_validation PASSED [ 40%]
tests/tool_execute_command/test_fix_example_mcp_testing_20240622.py::TestMCPToolingFramework::test_mcp_testing_utils_import PASSED [ 41%]
tests/tool_execute_command/test_fix_example_mcp_testing_20240622.py::TestMCPToolingFramework::test_environment_isolation PASSED [ 42%]
tests/tool_execute_command/test_fix_mcp_restart_and_new_code_loading_20241222.py::TestMCPRestartAndNewCodeLoading::test_code_change_detection PASSED [ 43%]
tests/tool_execute_command/test_fix_mcp_restart_and_new_code_loading_20241222.py::TestMCPRestartAndNewCodeLoading::test_index_js_startup_with_python_backend PASSED [ 44%]
tests/tool_execute_command/test_fix_mcp_restart_and_new_code_loading_20241222.py::TestMCPRestartAndNewCodeLoading::test_mcp_server_import_validation PASSED [ 45%]
tests/tool_execute_command/test_fix_mcp_restart_and_new_code_loading_20241222.py::TestMCPRestartAndNewCodeLoading::test_mcp_server_restart_simulation PASSED [ 47%]
tests/tool_execute_command/test_fix_mcp_restart_and_new_code_loading_20241222.py::TestMCPRestartAndNewCodeLoading::test_mcp_server_startup_without_errors PASSED [ 48%]
tests/tool_execute_command/test_fix_mcp_restart_and_new_code_loading_20241222.py::TestMCPRestartAndNewCodeLoading::test_mcp_server_syntax_validation PASSED [ 49%]
tests/tool_execute_command/test_fix_mcp_restart_and_new_code_loading_20241222.py::TestMCPRestartAndNewCodeLoading::test_new_update_server_config_logic_loading PASSED [ 50%]
tests/tool_execute_command/test_fix_mcp_restart_and_new_code_loading_20241222.py::TestMCPRestartAndNewCodeLoading::test_tools_list_generation PASSED [ 51%]
tests/tool_get_server_info/test_server_info.py::TestServerInfoCollector::test_get_user_host_with_mock PASSED [ 52%]
tests/tool_get_server_info/test_server_info.py::TestServerInfoCollector::test_parse_user_host PASSED [ 54%]
tests/tool_get_server_info/test_server_info.py::TestServerInfoCollector::test_validate_port PASSED [ 55%]
tests/tool_get_server_status/test_fix_quality_assurance_rules_20240622.py::QualityAssuranceRulesTest::test_cursorrules_quality_gates PASSED [ 56%]
tests/tool_get_server_status/test_fix_quality_assurance_rules_20240622.py::QualityAssuranceRulesTest::test_quality_assurance_workflow_compliance PASSED [ 57%]
tests/tool_get_server_status/test_fix_quality_assurance_rules_20240622.py::QualityAssuranceRulesTest::test_regression_directory_structure PASSED [ 58%]
tests/tool_get_server_status/test_fix_quality_assurance_rules_20240622.py::QualityAssuranceRulesTest::test_regression_test_content_quality FAILED [ 60%]
tests/tool_get_server_status/test_fix_quality_assurance_rules_20240622.py::QualityAssuranceRulesTest::test_regression_test_naming_convention PASSED [ 61%]
tests/tool_get_server_status/test_fix_quality_assurance_rules_20240622.py::QualityAssuranceRulesTest::test_regression_test_script_exists PASSED [ 62%]
tests/tool_list_servers/test_mcp_silent_config_regression.py::TestMCPSilentConfigRegression::test_constructor_without_force_interactive PASSED [ 63%]
tests/tool_list_servers/test_mcp_silent_config_regression.py::TestMCPSilentConfigRegression::test_mcp_silent_setup_auto_defaults PASSED [ 64%]
tests/tool_list_servers/test_mcp_silent_config_regression.py::TestMCPSilentConfigRegression::test_mcp_silent_setup_basic PASSED [ 65%]
tests/tool_list_servers/test_mcp_silent_config_regression.py::TestMCPSilentConfigRegression::test_mcp_silent_setup_validation FAILED [ 67%]
tests/tool_list_servers/test_mcp_silent_config_regression.py::TestMCPSilentConfigRegression::test_smart_input_detailed_error_messages FAILED [ 68%]
tests/tool_list_servers/test_mcp_silent_config_regression.py::TestMCPServerSilentIntegration::test_create_server_config_tool_error_handling SKIPPED [ 69%]
tests/tool_list_servers/test_mcp_silent_config_regression.py::TestMCPServerSilentIntegration::test_create_server_config_tool_silent_mode SKIPPED [ 70%]
tests/tool_sync_config/test_auto_sync_manager_implementation.py::TestAutoSyncManagerImplementation::test_auto_sync_manager_creation PASSED [ 71%]
tests/tool_sync_config/test_auto_sync_manager_implementation.py::TestAutoSyncManagerImplementation::test_auto_sync_manager_import PASSED [ 72%]
tests/tool_sync_config/test_auto_sync_manager_implementation.py::TestAutoSyncManagerImplementation::test_docker_environment_integration PASSED [ 74%]
tests/tool_sync_config/test_auto_sync_manager_implementation.py::TestAutoSyncManagerImplementation::test_error_handling_and_fallback PASSED [ 75%]
tests/tool_sync_config/test_auto_sync_manager_implementation.py::TestAutoSyncManagerImplementation::test_mcp_tools_sync_parameters PASSED [ 76%]
tests/tool_sync_config/test_auto_sync_manager_implementation.py::TestAutoSyncManagerImplementation::test_proftpd_file_validation PASSED [ 77%]
tests/tool_sync_config/test_auto_sync_manager_implementation.py::TestAutoSyncManagerImplementation::test_server_config_auto_sync_fields PASSED [ 78%]
tests/tool_sync_config/test_auto_sync_manager_implementation.py::TestAutoSyncManagerImplementation::test_sync_config_creation PASSED [ 80%]
tests/tool_sync_config/test_sync_config.py::TestSyncConfigCollector::test_configure_sync_skip PASSED [ 81%]
tests/tool_sync_config/test_sync_config_ui_enhancement.py::TestSyncConfigUIEnhancement::test_collect_sync_patterns_add_new FAILED [ 82%]
tests/tool_sync_config/test_sync_config_ui_enhancement.py::TestSyncConfigUIEnhancement::test_collect_sync_patterns_method_exists PASSED [ 83%]
tests/tool_sync_config/test_sync_config_ui_enhancement.py::TestSyncConfigUIEnhancement::test_collect_sync_patterns_with_defaults PASSED [ 84%]
tests/tool_sync_config/test_sync_config_ui_enhancement.py::TestSyncConfigUIEnhancement::test_configure_sync_disabled PASSED [ 85%]
tests/tool_sync_config/test_sync_config_ui_enhancement.py::TestSyncConfigUIEnhancement::test_configure_sync_enabled_full_config PASSED [ 87%]
tests/tool_sync_config/test_sync_config_ui_enhancement.py::TestSyncConfigUIEnhancement::test_configure_sync_method_exists PASSED [ 88%]
tests/tool_sync_config/test_sync_config_ui_enhancement.py::TestSyncConfigUIEnhancement::test_configure_sync_with_defaults PASSED [ 89%]
tests/tool_sync_config/test_sync_config_ui_enhancement.py::TestSyncConfigUIEnhancement::test_guided_setup_integration PASSED [ 90%]
tests/tool_update_server_config/test_fix_update_server_interactive_behavior_20241222.py::TestUpdateServerInteractiveBehavior::test_update_behavior_consistency_with_create PASSED [ 91%]
tests/tool_update_server_config/test_fix_update_server_interactive_behavior_20241222.py::TestUpdateServerInteractiveBehavior::test_update_server_docker_config_handling PASSED [ 92%]
tests/tool_update_server_config/test_fix_update_server_interactive_behavior_20241222.py::TestUpdateServerInteractiveBehavior::test_update_server_error_handling PASSED [ 94%]
tests/tool_update_server_config/test_fix_update_server_interactive_behavior_20241222.py::TestUpdateServerInteractiveBehavior::test_update_server_launches_interactive_interface PASSED [ 95%]
tests/tool_update_server_config/test_fix_update_server_interactive_behavior_20241222.py::TestUpdateServerInteractiveBehavior::test_update_server_preserves_existing_config PASSED [ 96%]
tests/tool_update_server_config/test_fix_update_server_interactive_behavior_20241222.py::TestUpdateServerInteractiveBehavior::test_update_server_relay_config_handling PASSED [ 97%]
tests/tool_update_server_config/test_interactive_update_server_config.py::test_interactive_update_server_config PASSED [ 98%]
tests/tool_update_server_config/test_interactive_update_server_config_prefill.py::test_interactive_update_server_config_prefill PASSED [100%]

=================================== FAILURES ===================================
____________________ test_interactive_create_server_config _____________________

    def test_interactive_create_server_config():
        # æµ‹è¯•å‰æ¸…ç†
        if os.path.exists(TEST_CONFIG_PATH):
            os.remove(TEST_CONFIG_PATH)
        # patch smart_inputï¼Œä¸¥æ ¼æŒ‰guided_setupå­—æ®µé¡ºåºæ¶ˆè´¹
        # æ™®é€šåœºæ™¯å­—æ®µé¡ºåºï¼šuser@host, port, docker_enabled, auto_sync_enabled
        PATCH_INPUTS = [
            "testuser@test-host-001",  # user@host
            "22",                    # ç«¯å£
            "2",                     # docker_enabled
            "2",                     # auto_sync_enabled
        ]
        with patch.object(EnhancedConfigManager, 'smart_input', side_effect=PATCH_INPUTS):
            manager = EnhancedConfigManager(config_path=TEST_CONFIG_PATH, force_interactive=True)
>           manager.guided_setup()

tests/tool_add_server_config/test_interactive_create_server_config.py:51: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
python/config_manager/main.py:289: in guided_setup
    docker_enabled = prefill['docker_enabled'] if prefill and 'docker_enabled' in prefill else parse_bool(get_input("æ˜¯å¦å¯ç”¨docker (1=å¯ç”¨, 2=ä¸ä½¿ç”¨, n=å¦, y=æ˜¯)", default="2"))
python/config_manager/main.py:226: in get_input
    return self.smart_input(prompt, default=default, validator=validator)
/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/unittest/mock.py:1093: in __call__
    return self._mock_call(*args, **kwargs)
/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/unittest/mock.py:1097: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock name='smart_input' id='4391529872'>
args = ('æ˜¯å¦å¯ç”¨docker (1=å¯ç”¨, 2=ä¸ä½¿ç”¨, n=å¦, y=æ˜¯)',)
kwargs = {'default': '2', 'validator': None}
effect = <list_iterator object at 0x105c529d0>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/unittest/mock.py:1154: StopIteration

The above exception was the direct cause of the following exception:

cls = <class '_pytest.runner.CallInfo'>
func = <function call_and_report.<locals>.<lambda> at 0x104db0670>
when = 'call'
reraise = (<class '_pytest.outcomes.Exit'>, <class 'KeyboardInterrupt'>)

    @classmethod
    def from_call(
        cls,
        func: Callable[[], TResult],
        when: Literal["collect", "setup", "call", "teardown"],
        reraise: type[BaseException] | tuple[type[BaseException], ...] | None = None,
    ) -> CallInfo[TResult]:
        """Call func, wrapping the result in a CallInfo.
    
        :param func:
            The function to call. Called without arguments.
        :type func: Callable[[], _pytest.runner.TResult]
        :param when:
            The phase in which the function is called.
        :param reraise:
            Exception or exceptions that shall propagate if raised by the
            function, instead of being wrapped in the CallInfo.
        """
        excinfo = None
        start = timing.time()
        precise_start = timing.perf_counter()
        try:
>           result: TResult | None = func()

../../Library/Python/3.9/lib/python/site-packages/_pytest/runner.py:341: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../Library/Python/3.9/lib/python/site-packages/_pytest/runner.py:242: in <lambda>
    lambda: runtest_hook(item=item, **kwds), when=when, reraise=reraise
../../Library/Python/3.9/lib/python/site-packages/pluggy/_hooks.py:513: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
../../Library/Python/3.9/lib/python/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
../../Library/Python/3.9/lib/python/site-packages/_pytest/threadexception.py:92: in pytest_runtest_call
    yield from thread_exception_runtest_hook()
../../Library/Python/3.9/lib/python/site-packages/_pytest/threadexception.py:68: in thread_exception_runtest_hook
    yield
../../Library/Python/3.9/lib/python/site-packages/_pytest/unraisableexception.py:95: in pytest_runtest_call
    yield from unraisable_exception_runtest_hook()
../../Library/Python/3.9/lib/python/site-packages/_pytest/unraisableexception.py:70: in unraisable_exception_runtest_hook
    yield
../../Library/Python/3.9/lib/python/site-packages/_pytest/logging.py:846: in pytest_runtest_call
    yield from self._runtest_for(item, "call")
../../Library/Python/3.9/lib/python/site-packages/_pytest/logging.py:829: in _runtest_for
    yield
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <CaptureManager _method='fd' _global_capturing=<MultiCapture out=<FDCapture 1 oldfd=6 _state='suspended' tmpfile=<_io....xtIOWrapper name='/dev/null' mode='r' encoding='utf-8'>> _state='suspended' _in_suspended=False> _capture_fixture=None>
item = <Function test_interactive_create_server_config>

    @hookimpl(wrapper=True)
    def pytest_runtest_call(self, item: Item) -> Generator[None]:
        with self.item_capture("call", item):
>           return (yield)
E           RuntimeError: generator raised StopIteration

../../Library/Python/3.9/lib/python/site-packages/_pytest/capture.py:898: RuntimeError
________ QualityAssuranceRulesTest.test_regression_test_content_quality ________

self = <test_fix_quality_assurance_rules_20240622.QualityAssuranceRulesTest testMethod=test_regression_test_content_quality>

    def test_regression_test_content_quality(self):
        """æµ‹è¯•3ï¼šéªŒè¯æµ‹è¯•å†…å®¹å®Œæ•´æ€§"""
        print("ğŸ§ª æµ‹è¯•å›å½’æµ‹è¯•å†…å®¹è´¨é‡...")
    
>       test_files = list(self.regression_dir.glob("test_fix_*.py"))
E       AttributeError: 'QualityAssuranceRulesTest' object has no attribute 'regression_dir'

tests/tool_get_server_status/test_fix_quality_assurance_rules_20240622.py:101: AttributeError
----------------------------- Captured stdout call -----------------------------
ğŸ§ª æµ‹è¯•å›å½’æµ‹è¯•å†…å®¹è´¨é‡...
________ TestMCPSilentConfigRegression.test_mcp_silent_setup_validation ________

self = <test_mcp_silent_config_regression.TestMCPSilentConfigRegression testMethod=test_mcp_silent_setup_validation>

    def test_mcp_silent_setup_validation(self):
        """æµ‹è¯•mcp_silent_setupçš„å‚æ•°éªŒè¯"""
        # æµ‹è¯•æ— æ•ˆçš„ä¸»æœºåœ°å€
        result = self.config_manager.mcp_silent_setup(
            name='invalid-host-server',
            host='invalid host with spaces',
            username='testuser'
        )
    
        self.assertFalse(result['success'], "æ— æ•ˆä¸»æœºåœ°å€åº”è¯¥å¯¼è‡´å¤±è´¥")
        self.assertIn('æ— æ•ˆçš„æœåŠ¡å™¨åœ°å€', result['error'])
    
        # æµ‹è¯•æ— æ•ˆçš„ç”¨æˆ·å
        result = self.config_manager.mcp_silent_setup(
            name='invalid-user-server',
            host='192.168.1.202',
            username='invalid@user'
        )
    
>       self.assertFalse(result['success'], "æ— æ•ˆç”¨æˆ·ååº”è¯¥å¯¼è‡´å¤±è´¥")
E       AssertionError: True is not false : æ— æ•ˆç”¨æˆ·ååº”è¯¥å¯¼è‡´å¤±è´¥

tests/tool_list_servers/test_mcp_silent_config_regression.py:126: AssertionError
____ TestMCPSilentConfigRegression.test_smart_input_detailed_error_messages ____

self = <test_mcp_silent_config_regression.TestMCPSilentConfigRegression testMethod=test_smart_input_detailed_error_messages>

    def test_smart_input_detailed_error_messages(self):
        """æµ‹è¯•smart_inputçš„è¯¦ç»†é”™è¯¯ä¿¡æ¯"""
        # æ¨¡æ‹ŸéMCPæ¨¡å¼
        self.config_manager.is_mcp_mode = False
    
        # æµ‹è¯•ä¸»æœºåœ°å€éªŒè¯
        with patch('builtins.input', side_effect=['invalid host', '192.168.1.100']):
            with patch('sys.stdout', new_callable=StringIO) as mock_stdout:
                result = self.config_manager.smart_input(
                    "ğŸŒ æœåŠ¡å™¨åœ°å€",
                    validator=self.config_manager.validate_hostname
                )
    
                output = mock_stdout.getvalue()
                self.assertIn('è¾“å…¥éªŒè¯å¤±è´¥', output)
                self.assertIn('æœåŠ¡å™¨åœ°å€ä¸èƒ½åŒ…å«ç©ºæ ¼', output)
                self.assertIn('æ­£ç¡®æ ¼å¼ç¤ºä¾‹', output)
                self.assertEqual(result, '192.168.1.100')
    
        # æµ‹è¯•ç”¨æˆ·åéªŒè¯ï¼ˆä½¿ç”¨æ— æ•ˆå­—ç¬¦è€Œä¸æ˜¯é•¿åº¦ï¼‰
        with patch('builtins.input', side_effect=['invalid@user', 'validuser']):
            with patch('sys.stdout', new_callable=StringIO) as mock_stdout:
                result = self.config_manager.smart_input(
                    "ğŸ‘¤ ç”¨æˆ·å",
                    validator=self.config_manager.validate_username
                )
    
                output = mock_stdout.getvalue()
>               self.assertIn('è¾“å…¥éªŒè¯å¤±è´¥', output)
E               AssertionError: 'è¾“å…¥éªŒè¯å¤±è´¥' not found in ''

tests/tool_list_servers/test_mcp_silent_config_regression.py:168: AssertionError
________ TestSyncConfigUIEnhancement.test_collect_sync_patterns_add_new ________

self = <test_sync_config_ui_enhancement.TestSyncConfigUIEnhancement testMethod=test_collect_sync_patterns_add_new>
mock_colored_print = <MagicMock name='colored_print' id='4391735008'>
mock_smart_input = <MagicMock name='smart_input' id='4391963040'>

    @patch('config_manager.main.EnhancedConfigManager.smart_input')
    @patch('config_manager.main.EnhancedConfigManager.colored_print')
    def test_collect_sync_patterns_add_new(self, mock_colored_print, mock_smart_input):
        """æµ‹è¯•7: _collect_sync_patternsæ–¹æ³•æ·»åŠ æ–°æ¨¡å¼"""
        log_test_output("æµ‹è¯•7: _collect_sync_patternsæ·»åŠ æ–°æ¨¡å¼", "INFO")
    
        try:
            from config_manager.main import EnhancedConfigManager
    
            # åˆ›å»ºé…ç½®ç®¡ç†å™¨å®ä¾‹
            config_manager = EnhancedConfigManager()
    
            # æ¨¡æ‹Ÿç”¨æˆ·è¾“å…¥ï¼ˆä¿ç•™é»˜è®¤å€¼ï¼Œæ·»åŠ æ–°å€¼ï¼‰
            mock_smart_input.side_effect = [
                "*.py",     # ä¿ç•™ç¬¬ä¸€ä¸ªé»˜è®¤å€¼
                "*.ts",     # æ·»åŠ æ–°çš„æ¨¡å¼
                "*.vue",    # æ·»åŠ æ–°çš„æ¨¡å¼
                ""          # å®Œæˆé…ç½®
            ]
    
            # è°ƒç”¨_collect_sync_patternsæ–¹æ³•
            result = config_manager._collect_sync_patterns(
                "åŒ…å«æ¨¡å¼",
                defaults=['*.py']
            )
    
            # éªŒè¯ç»“æœ
            self.assertIsInstance(result, list)
>           self.assertEqual(len(result), 3)
E           AssertionError: 1 != 3

tests/tool_sync_config/test_sync_config_ui_enhancement.py:293: AssertionError

During handling of the above exception, another exception occurred:

self = <test_sync_config_ui_enhancement.TestSyncConfigUIEnhancement testMethod=test_collect_sync_patterns_add_new>
mock_colored_print = <MagicMock name='colored_print' id='4391735008'>
mock_smart_input = <MagicMock name='smart_input' id='4391963040'>

    @patch('config_manager.main.EnhancedConfigManager.smart_input')
    @patch('config_manager.main.EnhancedConfigManager.colored_print')
    def test_collect_sync_patterns_add_new(self, mock_colored_print, mock_smart_input):
        """æµ‹è¯•7: _collect_sync_patternsæ–¹æ³•æ·»åŠ æ–°æ¨¡å¼"""
        log_test_output("æµ‹è¯•7: _collect_sync_patternsæ·»åŠ æ–°æ¨¡å¼", "INFO")
    
        try:
            from config_manager.main import EnhancedConfigManager
    
            # åˆ›å»ºé…ç½®ç®¡ç†å™¨å®ä¾‹
            config_manager = EnhancedConfigManager()
    
            # æ¨¡æ‹Ÿç”¨æˆ·è¾“å…¥ï¼ˆä¿ç•™é»˜è®¤å€¼ï¼Œæ·»åŠ æ–°å€¼ï¼‰
            mock_smart_input.side_effect = [
                "*.py",     # ä¿ç•™ç¬¬ä¸€ä¸ªé»˜è®¤å€¼
                "*.ts",     # æ·»åŠ æ–°çš„æ¨¡å¼
                "*.vue",    # æ·»åŠ æ–°çš„æ¨¡å¼
                ""          # å®Œæˆé…ç½®
            ]
    
            # è°ƒç”¨_collect_sync_patternsæ–¹æ³•
            result = config_manager._collect_sync_patterns(
                "åŒ…å«æ¨¡å¼",
                defaults=['*.py']
            )
    
            # éªŒè¯ç»“æœ
            self.assertIsInstance(result, list)
            self.assertEqual(len(result), 3)
            self.assertIn('*.py', result)
            self.assertIn('*.ts', result)
            self.assertIn('*.vue', result)
    
            log_test_output("âœ… _collect_sync_patternsæ­£ç¡®æ·»åŠ æ–°æ¨¡å¼", "SUCCESS")
    
        except Exception as e:
>           self.fail(f"æµ‹è¯•_collect_sync_patternsæ·»åŠ æ–°æ¨¡å¼å¤±è´¥: {str(e)}")
E           AssertionError: æµ‹è¯•_collect_sync_patternsæ·»åŠ æ–°æ¨¡å¼å¤±è´¥: 1 != 3

tests/tool_sync_config/test_sync_config_ui_enhancement.py:301: AssertionError
----------------------------- Captured stdout call -----------------------------
â„¹ï¸ å¼€å§‹æµ‹è¯•: TestSyncConfigUIEnhancement
â„¹ï¸ æµ‹è¯•7: _collect_sync_patternsæ·»åŠ æ–°æ¨¡å¼
â„¹ï¸ å®Œæˆæµ‹è¯•: TestSyncConfigUIEnhancement
=========================== short test summary info ============================
FAILED tests/tool_add_server_config/test_interactive_create_server_config.py::test_interactive_create_server_config
FAILED tests/tool_get_server_status/test_fix_quality_assurance_rules_20240622.py::QualityAssuranceRulesTest::test_regression_test_content_quality
FAILED tests/tool_list_servers/test_mcp_silent_config_regression.py::TestMCPSilentConfigRegression::test_mcp_silent_setup_validation
FAILED tests/tool_list_servers/test_mcp_silent_config_regression.py::TestMCPSilentConfigRegression::test_smart_input_detailed_error_messages
FAILED tests/tool_sync_config/test_sync_config_ui_enhancement.py::TestSyncConfigUIEnhancement::test_collect_sync_patterns_add_new
======== 5 failed, 78 passed, 2 skipped, 5 warnings in 72.64s (0:01:12) ========
